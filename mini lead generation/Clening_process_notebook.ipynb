{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Organizing Companies by Industry - Jupyter Notebook\n",
        "This notebook documents the process of organizing companies scraped from LinkedIn by their **industry** into separate Xlsx files.\n",
        "\n",
        "Since the retrieved data is scraped from the search results, there's already no duplicates hence there's no need for advanced data manipulation techniques which will make the task more simple and less time consuming.  \n",
        "\n",
        "The purpose of this notebook is to demonstrate how to efficiently manage and organize large datasets, particularly when dealing with **categorical data** such as **industry types**.\n"
      ],
      "metadata": {
        "id": "j_hgjFljFVJ8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# First Step:\n",
        "To proceed, I begun with the setup which consists of importing the necessary Libraries. In this case, In opted for the ***Pandas*** library."
      ],
      "metadata": {
        "id": "AIeb7zeCGTGQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "pWumZkXtGmRt"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Second Step:\n",
        "In the next step, the program needs to **read** the scraped data already stored in the file \"linkedin.csv\" and load it into a data frame.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "8AwUo5rvGrB1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scraped_data = pd.read_csv('linkedin.csv')"
      ],
      "metadata": {
        "id": "Kla39o19HTPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Third Step:\n",
        "The third step is to organize the data in way that it's grouped by Industry of each company."
      ],
      "metadata": {
        "id": "6exFFM0dHUxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "industry_groups = scraped_data.groupby('Industry')\n"
      ],
      "metadata": {
        "id": "m8yAVQSDIX6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fourth Step:\n",
        "This step involves organizing the data and saving it by the Industry name to be more convinient for the user and to avoid time consumption while searching for the desired data. The data is saved in Xlsx file."
      ],
      "metadata": {
        "id": "LanRY738Ipuj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for industry, group in scraped_data.groupby('Industry'):\n",
        "    filename = f'{industry}_companies.xlsx'\n",
        "    group.to_excel(filename, index=False)\n"
      ],
      "metadata": {
        "id": "uGRTe2_iIxIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've successfully organized companies scraped from LinkedIn by their industry into separate Xlsx files.\n",
        "\n",
        "This process allows for better management and analysis of the data, making it easier to perform tasks such as industry-specific analysis or data visualization.\n",
        "\n"
      ],
      "metadata": {
        "id": "tRa1wu_BJirE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a better reference, here's the whole code for cleaning the data."
      ],
      "metadata": {
        "id": "m8Luy5WoJ9j_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read the CSV file generated by your scraping script\n",
        "scraped_data = pd.read_csv('linkedin.csv')\n",
        "\n",
        "# Organize companies with the same industry into one separate file\n",
        "for industry, group in scraped_data.groupby('Industry'):\n",
        "    filename = f'{industry}_companies.xlsx'\n",
        "    group.to_excel(filename, index=False)\n"
      ],
      "metadata": {
        "id": "IQAYS-bWKDjH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}